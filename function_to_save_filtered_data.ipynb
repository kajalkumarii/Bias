{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = \"/home/kkumari/PhD/fish-data/processed-data-long-term-free-swim/\"\n",
    "\n",
    "def read_files_keep_peak(file_path):\n",
    "    # Extract file name from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Read the file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Filter rows where 'time_stamp_peak' is not NaN\n",
    "    df = df[df['time_stamp_peak'].notna()]\n",
    "    \n",
    "    # Add 'fish_id' and 'trial_id' columns\n",
    "    df['fish_id'] = file_name[:2]\n",
    "    df['trial_id'] = file_name[4:5]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get all file paths in the folder\n",
    "# file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "# # Apply the function to each file\n",
    "# filtered_files = [read_files_keep_peak(f) for f in file_paths]\n",
    "# # Concatenate all the filtered dataframes\n",
    "# df = pd.concat(filtered_files, ignore_index=True)\n",
    "# # Display the first few rows\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       realtime     fishz     fishy     fishx    start_time  smooth_fishx   \n",
      "0  1.660129e+09 -0.043855  0.093397  0.041106  1.660129e+09      0.040980  \\\n",
      "1  1.660129e+09 -0.043855  0.093397  0.041106  1.660129e+09      0.041031   \n",
      "2  1.660129e+09 -0.043855  0.093397  0.041106  1.660129e+09      0.041081   \n",
      "3  1.660129e+09 -0.043855  0.093397  0.041106  1.660129e+09      0.041131   \n",
      "4  1.660129e+09 -0.043855  0.093397  0.041106  1.660129e+09      0.041182   \n",
      "\n",
      "   smooth_fishy  smooth_fishz       dx        dy        dz  velocity   \n",
      "0      0.093500     -0.043822  0.00000  0.000000  0.000000  0.000000  \\\n",
      "1      0.093459     -0.043830  0.00005 -0.000041 -0.000008  0.006537   \n",
      "2      0.093418     -0.043839  0.00005 -0.000041 -0.000008  0.006537   \n",
      "3      0.093378     -0.043847  0.00005 -0.000041 -0.000008  0.006537   \n",
      "4      0.093337     -0.043855  0.00005 -0.000041 -0.000008  0.006537   \n",
      "\n",
      "   time_stamp  angle_degrees  peak_angles  time_stamp_peak   \n",
      "0    0.000711            NaN          NaN              NaN  \\\n",
      "1    0.000711            NaN          NaN              NaN   \n",
      "2    0.000711            NaN          NaN              NaN   \n",
      "3    0.000711            NaN          NaN              NaN   \n",
      "4    0.000711            NaN          NaN              NaN   \n",
      "\n",
      "   interbout_duration  turn_bias fish_id trial_id  \n",
      "0                 NaN        NaN      13        1  \n",
      "1                 NaN        NaN      13        1  \n",
      "2                 NaN        NaN      13        1  \n",
      "3                 NaN        NaN      13        1  \n",
      "4                 NaN        NaN      13        1  \n"
     ]
    }
   ],
   "source": [
    "#  craete a file with wdropping nan values from time_stamp_peak\n",
    "\n",
    "def read_files_without_droping_nan_peak(file_path):\n",
    "    # Extract file name from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Read the file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add 'fish_id' and 'trial_id' columns\n",
    "    df['fish_id'] = file_name[:2]\n",
    "    df['trial_id'] = file_name[4:5]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Get all file paths in the folder\n",
    "file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "# Apply the function to each file\n",
    "process_files = [read_files_without_droping_nan_peak(f) for f in file_paths]\n",
    "# Concatenate all the filtered dataframes\n",
    "df_nans = pd.concat(process_files, ignore_index=True)\n",
    "# Display the first few rows\n",
    "print(df_nans.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save df as a csv file\n",
    "# df.to_csv(\"/home/kkumari/PhD/fish-data/processed-data-long-term-free-swim/collated_data_for_angle_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nans.to_csv(\"/home/kkumari/PhD/fish-data/processed-data-long-term-free-swim/collated_data_for_nans_angle_analysis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
