{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks\n",
    "import os\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "from scipy.signal import find_peaks\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/kkumari/PhD/fish-data/long-term-free-swim/\"\n",
    "# path = \"C:/PhD/long_term_free_swim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cartesian to spherical coordinates\n",
    "def cart2sph(x,y,z):\n",
    "    azimuth = np.arctan2(y,x)\n",
    "    elevation = np.arctan2(z, np.sqrt(x**2 + y**2))\n",
    "    R = np.sqrt(x**2 + y**2 + z**2)\n",
    "    return(azimuth, elevation, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a list of file paths and a list of desired columns as input,\n",
    "# and returns a dictionary that collates data from the files.\n",
    "def load_and_collate_data(all_files: List[str], desired_cols: List[str]) -> dict:\n",
    "\n",
    "    # Create an empty dictionary to store the collated data\n",
    "    fish_data = {}\n",
    "\n",
    "    # Iterate over each file path in the given list of files\n",
    "    for file in tqdm(all_files[0:3], desc=\"Processing files\"):\n",
    "        # Open the file using gzip and read its contents using pandas\n",
    "        with gzip.open(file, 'rb') as f:\n",
    "            df = pd.read_csv(f, usecols=desired_cols)\n",
    "\n",
    "        # Extract the fish ID from the file path\n",
    "        fish_id = os.path.basename(file)[:2]\n",
    "\n",
    "        # Check if the fish ID already exists in the fish_data dictionary\n",
    "        if fish_id not in fish_data:\n",
    "            # If the fish ID does not exist, create a new entry with an empty dataframe and list of files\n",
    "            fish_data[fish_id] = {'df': [], 'files': []}\n",
    "\n",
    "        # Append the dataframe and file path to the corresponding fish ID entry in the fish_data dictionary\n",
    "        fish_data[fish_id]['df'].append(df)\n",
    "        fish_data[fish_id]['files'].append(file)\n",
    "\n",
    "    # Return the collated fish_data dictionary\n",
    "    return fish_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(df_diff):\n",
    "    dx = df_diff[\"fishx\"].interpolate(method='bfill')\n",
    "    dy = df_diff[\"fishy\"].interpolate(method='bfill')\n",
    "    dz = df_diff[\"fishz\"].interpolate(method='bfill')\n",
    "\n",
    "    angle_wrapped = np.arctan2(dy, dx)\n",
    "    last = 0\n",
    "    angles = []\n",
    "    for phi in angle_wrapped:\n",
    "        while phi < last - np.pi:\n",
    "            phi += 2 * np.pi\n",
    "        while phi > last + np.pi:\n",
    "            phi -= 2 * np.pi\n",
    "        last = phi\n",
    "        angles.append(phi)\n",
    "\n",
    "    return angles\n",
    "\n",
    "\n",
    "def create_velocity_dataframe(df, fHz):\n",
    "    df_diff = df.diff(periods=1, axis=0)\n",
    "\n",
    "    dt = 1 / fHz\n",
    "    velocity = np.sqrt(df_diff[\"dx\"] ** 2 + df_diff[\"dy\"] ** 2 + df_diff[\"dz\"] ** 2) / dt\n",
    "\n",
    "    velocity_dataframe = pd.DataFrame({\n",
    "        'Time': df['realtime'],\n",
    "        'Velocity': velocity,\n",
    "        'X': df['fishx'],\n",
    "        'Y': df['fishy'],\n",
    "        'Z': df['fishz'],\n",
    "        'Angle': calculate_angles(df_diff)\n",
    "    })\n",
    "\n",
    "    velocity_dataframe.interpolate(inplace=True)\n",
    "\n",
    "    return velocity_dataframe\n",
    "\n",
    "\n",
    "def calculate_additional_variables_per_trial(fish_data: dict, fHz: int):\n",
    "    dangles_dict = {}\n",
    "    for fish_id, data in fish_data.items():\n",
    "        data['angles'] = []\n",
    "        data['avg_velocity'] = []\n",
    "        data['angles_at_peaks'] = []\n",
    "        data['peak_times'] = []\n",
    "        data['dangles'] = []\n",
    "        data['velocity_dataframe'] = []\n",
    "        data['peaks'] = []\n",
    "        data['velocity'] = []\n",
    "        data['angles_at_peaks_normalized'] = []\n",
    "        data['angles_at_peaks_unwrapped'] = []\n",
    "\n",
    "        for df in data['df']:\n",
    "            df[\"realtime\"] = df[\"realtime\"] - df[\"realtime\"].iloc[0]\n",
    "\n",
    "            df_diff = df.diff(periods=1, axis=0)\n",
    "            steps = np.sqrt(df[\"fishx\"] ** 2 + df[\"fishy\"] ** 2 + df[\"fishz\"] ** 2)\n",
    "            df[\"steps\"] = steps\n",
    "            max_stepsize = 0.02\n",
    "            large_steps = df['steps'] > max_stepsize\n",
    "            w = 10\n",
    "            selected_columns = ['fishz', 'fishy', 'fishx']\n",
    "            large_step_indices = large_steps[large_steps].index.values\n",
    "            for i in range(0, len(large_step_indices)):\n",
    "                lsi = large_step_indices[i]\n",
    "                df.loc[lsi - w:lsi + w, selected_columns] = np.nan\n",
    "\n",
    "            err = 0.001\n",
    "            df.loc[df['fishz'] < -(0.09 + err), selected_columns] = np.nan\n",
    "            df.loc[df['fishz'] > 0 + err, selected_columns] = np.nan\n",
    "            zoffset = 0.11\n",
    "            azimuth, elevation, R = cart2sph(df['fishx'], df['fishy'], df['fishz'] - zoffset)\n",
    "            err = 0.005\n",
    "            df.loc[R > 0.2 + err, selected_columns] = np.nan\n",
    "            df.loc[R < 0.11 - err, selected_columns] = np.nan\n",
    "\n",
    "            df[\"dx\"] = df_diff[\"fishx\"].interpolate(method='bfill')\n",
    "            df[\"dy\"] = df_diff[\"fishy\"].interpolate(method='bfill')\n",
    "            df[\"dz\"] = df_diff[\"fishz\"].interpolate(method='bfill')\n",
    "\n",
    "            angles = calculate_angles(df_diff)\n",
    "            data['angles'].append(angles)\n",
    "\n",
    "            dt = 1 / fHz\n",
    "            velocity = np.sqrt(df[\"dx\"] ** 2 + df[\"dy\"] ** 2 + df[\"dz\"] ** 2) / dt\n",
    "            avg_velocity = velocity.median()\n",
    "            data['avg_velocity'].append(avg_velocity)\n",
    "\n",
    "            height = (0.1, 0.5)\n",
    "            frames_btw_2bouts = round(fHz / 10)\n",
    "            bout_width = round(fHz / 100)\n",
    "            prominence = 0.05\n",
    "            peaks, _ = find_peaks(velocity, height=height, distance=frames_btw_2bouts, width=bout_width,\n",
    "                                  prominence=prominence)\n",
    "            angles_at_peaks = [angles[i] for i in peaks]\n",
    "            data['angles_at_peaks'].append(angles_at_peaks)\n",
    "\n",
    "            peak_times = [df[\"realtime\"].iloc[i] for i in peaks]\n",
    "            data['peak_times'].append(peak_times)\n",
    "\n",
    "            angles_at_peaks_normalized = np.mod(angles_at_peaks, 2 * np.pi) - np.pi\n",
    "            angles_at_peaks_unwrapped = np.unwrap(angles_at_peaks_normalized)\n",
    "            angles_at_peaks_diff = np.diff(angles_at_peaks_unwrapped)\n",
    "            angles_at_peaks_diff = np.mod(angles_at_peaks_diff + np.pi, 2 * np.pi) - np.pi\n",
    "            dangles = angles_at_peaks_diff\n",
    "            data['dangles'].append(dangles)\n",
    "\n",
    "            velocity_dataframe = create_velocity_dataframe(df, fHz)\n",
    "            data['velocity_dataframe'].append(velocity_dataframe)\n",
    "\n",
    "            dangles_dict[fish_id] = dangles\n",
    "\n",
    "    return dangles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_turning_angle_properties(dangles):\n",
    "    # Calculate the number of clockwise and counterclockwise turns\n",
    "    counterclockwise_turns = np.sum(dangles > 0)\n",
    "    clockwise_turns = np.sum(dangles < 0)\n",
    "\n",
    "    # Calculate probability of clockwise and counterclockwise turns\n",
    "    probability_counterclockwise_turns = counterclockwise_turns / (counterclockwise_turns + clockwise_turns)\n",
    "    probability_clockwise_turns = clockwise_turns / (counterclockwise_turns + clockwise_turns)\n",
    "\n",
    "    # Get sequence of right and left turns as 1 and -1\n",
    "    turns = np.sign(dangles)\n",
    "\n",
    "    def streak_lengths(turns):\n",
    "        if len(turns) == 0:\n",
    "            return np.array([])  # return empty array for empty input\n",
    "\n",
    "        streaks = []\n",
    "        current_streak = 1  # start with a streak of 1\n",
    "\n",
    "        for i in range(1, len(turns)):\n",
    "            if turns[i] == turns[i - 1]:  # if current turn is same as previous\n",
    "                current_streak += 1  # increment streak count\n",
    "            else:  # if current turn is different\n",
    "                streaks.append(current_streak)  # add the streak to the list\n",
    "                current_streak = 1  # reset streak count\n",
    "\n",
    "        streaks.append(current_streak)  # add the last streak\n",
    "        return np.array(streaks)\n",
    "\n",
    "    streaks = streak_lengths(turns)\n",
    "\n",
    "    # Now let's bundle all this data into a dictionary and return it\n",
    "    turning_properties = {\n",
    "        'counterclockwise_turns': counterclockwise_turns,\n",
    "        'clockwise_turns': clockwise_turns,\n",
    "        'probability_counterclockwise_turns': probability_counterclockwise_turns,\n",
    "        'probability_clockwise_turns': probability_clockwise_turns,\n",
    "        'turns': turns,\n",
    "        'streaks': streaks\n",
    "    }\n",
    "\n",
    "    return turning_properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = sorted(glob.glob(os.path.join(path, \"*.csv.gz\")))[:5]  # Modify the number of files to process\n",
    "desired_cols = ['fishx', 'fishy', 'fishz', 'realtime']\n",
    "fish_data = load_and_collate_data(all_files, desired_cols)\n",
    "dangles_dict = calculate_additional_variables_per_trial(fish_data, fHz=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turning_properties_dict = calculate_turning_angle_properties(fish_data['dangles'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
